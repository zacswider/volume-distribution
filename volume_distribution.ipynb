{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# markdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import vg\n",
    "import time\n",
    "import joblib\n",
    "import napari\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy import spatial\n",
    "from skimage import filters\n",
    "from skimage import morphology\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage as ndi\n",
    "from tifffile import imread, imwrite\n",
    "from skimage.morphology import label\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage.morphology import binary_erosion\n",
    "from skimage.measure import regionprops, regionprops_table\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "def wipe_layers(viewer_name):\n",
    "    '''\n",
    "    Delete all layers in the viewer objected\n",
    "    '''\n",
    "    layers = viewer_name.layers\n",
    "    while len(layers) > 0:\n",
    "        layers.remove(layers[0])\n",
    "\n",
    "def remove_large_objects(labels_array: np.ndarray, max_size: int) -> np.ndarray:\n",
    "    ''' \n",
    "    Remove all objects in a mask above a specific threshold\n",
    "    '''\n",
    "    out = np.copy(labels_array)\n",
    "    component_sizes = np.bincount(labels_array.ravel()) # count the number of pixels in different labels\n",
    "    too_big = component_sizes > max_size\n",
    "    too_big_mask = too_big[labels_array]\n",
    "    out[too_big_mask] = 0\n",
    "    return out\n",
    "\n",
    "def return_points(labels_array: np.ndarray, label_ID: int) -> np.ndarray:\n",
    "    '''\n",
    "    Return the points in a mask that belong to a specific label\n",
    "    ---\n",
    "    Parameters:\n",
    "    labels_array: np.ndarray an ndArray of labels\n",
    "    label_ID: int the label ID of the label whos points you want to calculate\n",
    "    ---\n",
    "    Returns:\n",
    "    points: np.ndarray an ndArray of shape (n,3) where n is the number of points in the label\n",
    "    and dim1 is the x,y,z coordinates of the points\n",
    "    '''\n",
    "    points = np.column_stack(np.where(labels_array == label_ID))\n",
    "    return points\n",
    "\n",
    "def find_label_density(label_points: np.ndarray) -> float:\n",
    "    '''\n",
    "    Calculate the bounding box for a point cloud and return the density of points in the bounding box\n",
    "    ---\n",
    "    Parameters:\n",
    "    label_points: np.ndarray the array point coordinates for a given label\n",
    "    ---\n",
    "    Returns:\n",
    "    np.nan if the label is 0, or if the label has no length\n",
    "    density (float) the number of points in the label divided by the volume of the bounding box\n",
    "    '''\n",
    "\n",
    "    x = label_points.T[0]\n",
    "    y = label_points.T[1]\n",
    "    z = label_points.T[2]\n",
    "    num_points = len(x)\n",
    "    x_min = np.min(x)\n",
    "    x_max = np.max(x)\n",
    "    y_min = np.min(y)\n",
    "    y_max = np.max(y)\n",
    "    z_min = np.min(z)\n",
    "    z_max = np.max(z)\n",
    "    # add 1 to prevent division by 0\n",
    "    x_range = (x_max - x_min) + 1\n",
    "    y_range = (y_max - y_min) + 1\n",
    "    z_range = (z_max - z_min) + 1\n",
    "    vol = x_range * y_range * z_range\n",
    "    density = num_points / vol\n",
    "    return density\n",
    "\n",
    "def print_label_props(source: np.ndarray, label_num: int) -> None:\n",
    "    '''\n",
    "    Print the properties of a label in a mask\n",
    "    ---\n",
    "    Parameters:\n",
    "    source: np.ndarray the mask containing the label\n",
    "    label_num: int the label number of the label you want to print the properties of\n",
    "    ---\n",
    "    Returns:\n",
    "    None\n",
    "    '''\n",
    "    label_points = return_points(source, label_num)\n",
    "    density = find_label_density(label_points)\n",
    "    size = label_points.shape[0]\n",
    "    print(f'Label {label_num} has:')\n",
    "    print(f'{size:,} points.')\n",
    "    print(f'density of {round(density,4):,}')\n",
    "\n",
    "def get_cube(source: np.ndarray, label_num: int) -> np.ndarray:\n",
    "    '''\n",
    "    Return a cube of the label in a mask\n",
    "    ---\n",
    "    Parameters:\n",
    "    source: np.ndarray the mask containing the label\n",
    "    label_num: int the label number of the label you want isolate\n",
    "    ---\n",
    "    Returns:\n",
    "    cube: np.ndarray the cube of the label\n",
    "    '''\n",
    "    label_points = return_points(source, label_num)\n",
    "    x = label_points.T[0]\n",
    "    y = label_points.T[1]\n",
    "    z = label_points.T[2]\n",
    "    x_min = np.min(x) - 1\n",
    "    x_max = np.max(x) + 2\n",
    "    y_min = np.min(y) - 1\n",
    "    y_max = np.max(y) + 2\n",
    "    z_min = np.min(z) - 1\n",
    "    z_max = np.max(z) + 2\n",
    "    #cube = source[x_min:x_max+1, y_min:y_max+1, z_min:z_max+1]\n",
    "    return x_min, x_max, y_min, y_max, z_min, z_max\n",
    "\n",
    "def apply_cube(source: np.ndarray, cube: tuple) -> np.ndarray:\n",
    "    '''\n",
    "    Crop an ndArray with a cube\n",
    "    ---\n",
    "    Parameters:\n",
    "    source: np.ndarray the array to crop\n",
    "    cube: tuple containing the x_min, x_max, y_min, y_max, z_min, z_max\n",
    "    ---\n",
    "    Returns:\n",
    "    out: np.ndarray array with the cube applied\n",
    "    '''\n",
    "    x_min, x_max, y_min, y_max, z_min, z_max = cube\n",
    "    out = source[x_min:x_max, y_min:y_max, z_min:z_max]\n",
    "    return out\n",
    "\n",
    "def get_long_axis(cubed_label: np.ndarray, line_length = 75):\n",
    "    '''\n",
    "    Get the longest axis of an cubed_label\n",
    "    ---\n",
    "    Parameters:\n",
    "    cubed_label: np.ndarray the cubed_label to get the longest axis of\n",
    "    ---\n",
    "    Returns:\n",
    "    linepts: np.ndarray the points of the longest axis\n",
    "    '''\n",
    "    if cubed_label.dtype == 'bool':\n",
    "        coords = np.column_stack(np.where(cubed_label == True))\n",
    "    else:\n",
    "        label_identify = [i for i in np.unique(cubed_label) if i != 0][0]\n",
    "        coords = np.column_stack(np.where(cubed_label == label_identify))\n",
    "    if coords.shape[0] > 1000:\n",
    "        sampling_interval = coords.shape[0] // 1000\n",
    "    else:\n",
    "        sampling_interval = 1    \n",
    "\n",
    "    np.random.shuffle(coords)\n",
    "    subsampled = coords[::sampling_interval]\n",
    "    datamean = subsampled.mean(axis=0)\n",
    "    uu, dd, vv = np.linalg.svd(subsampled - datamean)\n",
    "    linepts = vv[0] * np.mgrid[-line_length:line_length:2j][:, np.newaxis]\n",
    "    linepts += datamean\n",
    "    return vv[0], linepts\n",
    "\n",
    "def view_saved_files(file_path: str) -> None:\n",
    "    ''' \n",
    "    Fxn for visualizing saved output files.\n",
    "    '''\n",
    "    dedicated_file_viewer = napari.Viewer()\n",
    "    contents = [c for c in os.listdir(file_path) if not c.startswith('.')]\n",
    "    for content in contents:\n",
    "        if content.endswith('.tif'):\n",
    "            if 'tub' in content or 'PI' in content:\n",
    "                dedicated_file_viewer.add_image(imread(os.path.join(file_path, content)), name=content.split('.')[0], blending='additive', visible=False)\n",
    "            else:\n",
    "                dedicated_file_viewer.add_labels(imread(os.path.join(file_path, content)), name=content.split('.')[0], blending='additive')\n",
    "        elif content.endswith('.txt'):\n",
    "            nums = np.loadtxt(os.path.join(file_path, content))\n",
    "            if nums.ndim == 1:\n",
    "                dedicated_file_viewer.add_points(nums, name=content.split('.')[0], face_color='white', blending='additive')\n",
    "            elif nums.ndim == 2:\n",
    "                dedicated_file_viewer.add_shapes(nums, shape_type='line', name=content.split('.')[0], edge_color='white', blending='additive')\n",
    "        else:\n",
    "            print(f'file \"{content}\" not imported to viewer')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the napari Viewer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt \n",
    "viewer = napari.Viewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_dir = '/Volumes/bigData/wholeMount_volDist/220712_Fix_Emb_Flvw_Chn1GAP_PI_aTub647_Processed/N2V_Denoised/0_Analysis_01'\n",
    "subdirs = [d for d in os.listdir(analysis_dir) if os.path.isdir(os.path.join(analysis_dir, d))]\n",
    "\n",
    "# load the spindle classifier\n",
    "classifier_path = os.path.join(os.getcwd(), 'spindle_classifier/spindle_classifier.joblib')\n",
    "classifier = joblib.load(classifier_path)\n",
    "\n",
    "# create save directory\n",
    "data_save_dir = os.path.join(analysis_dir, '0_data_cubes')\n",
    "if not os.path.exists(data_save_dir):\n",
    "    os.mkdir(data_save_dir)\n",
    "\n",
    "\n",
    "for subdir in tqdm(subdirs):\n",
    "\n",
    "    # make a save directory for this embryo\n",
    "    emb_save_dir = os.path.join(data_save_dir, subdir)\n",
    "    if not os.path.exists(emb_save_dir):\n",
    "        os.makedirs(emb_save_dir)\n",
    "\n",
    "    # define file paths and load data\n",
    "    emb_type, emb_num = subdir.split('_')\n",
    "    segmentations_name = f'220712_Fix_Emb_Flvw_Chn1GAP_PI_aTub647_{emb_type}_{emb_num}-Z01_PI_16bit_scaleZ_sbdl2_16bit_seg.npy'\n",
    "    dog_tub_name = f'220712_Fix_Emb_Flvw_Chn1GAP_PI_aTub647_{emb_type}_{emb_num}-Z01_Tub_16bit_scaleZ_sbdl2_16bit.tif'\n",
    "    raw_tub_name = f'220712_Fix_Emb_Flvw_Chn1GAP_PI_aTub647_{emb_type}_{emb_num}-Z01_Tub_16bit_scaleZ.tif'\n",
    "    pi_name = f'220712_Fix_Emb_Flvw_Chn1GAP_PI_aTub647_{emb_type}_{emb_num}-Z01_PI_16bit_scaleZ_sbdl2_16bit.tif'\n",
    "\n",
    "    data_load_dir = os.path.join(analysis_dir, subdir)\n",
    "    masks = np.load(os.path.join(data_load_dir, segmentations_name), allow_pickle=True).item()['masks']\n",
    "    tub = imread(os.path.join(data_load_dir, dog_tub_name))\n",
    "    tub_raw = imread(os.path.join(data_load_dir, raw_tub_name))\n",
    "    pi = imread(os.path.join(data_load_dir, pi_name))\n",
    "\n",
    "    # coarsly filter the masks of poor segmentations\n",
    "    minimum_size = 250000\n",
    "    maximum_size = 1000000\n",
    "    minimum_density = 0.21\n",
    "\n",
    "    filtered_masks = clear_border(masks)\n",
    "    filtered_masks = morphology.remove_small_objects(filtered_masks, min_size=minimum_size, connectivity=1)\n",
    "    filtered_masks = remove_large_objects(filtered_masks, max_size=maximum_size)\n",
    "    remaining_labels = [label for label in np.unique(filtered_masks) if label != 0]\n",
    "    print('Calculating point clouds...')\n",
    "    label_pcs = [return_points(masks, label_ID) for label_ID in tqdm(remaining_labels)]\n",
    "    densities = [find_label_density(pc) for pc in label_pcs]\n",
    "\n",
    "    for ind, id in enumerate(remaining_labels):\n",
    "        if id in remaining_labels and densities[ind] < minimum_density:\n",
    "            filtered_masks[filtered_masks == id] = 0\n",
    "\n",
    "    # Establish the remaining labels for the embryo and loop through each cell\n",
    "    final_labels = [label for label in np.unique(filtered_masks) if label != 0]\n",
    "    for curr_mask_id in final_labels:\n",
    "        wipe_layers(viewer)\n",
    "\n",
    "        # isolate the current mask as bolean array\n",
    "        curr_mask = filtered_masks == curr_mask_id\n",
    "\n",
    "        # get the coordinate of the bounding cube for the current mask ID. Apply it to the labels and images\n",
    "        cube_dims = get_cube(filtered_masks, curr_mask_id)\n",
    "        cubed_label = apply_cube(curr_mask, cube_dims)\n",
    "        cubed_tub = apply_cube(tub, cube_dims)\n",
    "        cubed_tub_raw = apply_cube(tub_raw, cube_dims)\n",
    "        cubed_PI = apply_cube(pi, cube_dims)\n",
    "\n",
    "        # get the mask coordinates, centroid, and long axis\n",
    "        mask_coords = np.column_stack(np.where(cubed_label == True))\n",
    "        cell_centroid = mask_coords.mean(axis=0)\n",
    "        cell_long_vect, cell_long_line = get_long_axis(cubed_label)\n",
    "\n",
    "        # erode the mask to eliminate some cortical signal\n",
    "        eroded_mask = binary_erosion(cubed_label, footprint=np.ones((3, 3, 3)))\n",
    "        for i in range(10):\n",
    "            eroded_mask = binary_erosion(eroded_mask)\n",
    "\n",
    "        # get the tubulin signal from the remaining region and define an Otsu threshold\n",
    "        remaining_tub = np.zeros(shape=cubed_label.shape)\n",
    "        remaining_tub[eroded_mask] = cubed_tub[eroded_mask]\n",
    "        remaining_vals = cubed_tub[eroded_mask].ravel()\n",
    "        thresh_val = threshold_otsu(remaining_vals)\n",
    "        thresh_mask = label(remaining_tub > thresh_val)\n",
    "\n",
    "        # get number of remaining labels\n",
    "        num_tub_labels_b4_filter = [label for label in np.unique(thresh_mask) if label != 0]\n",
    "\n",
    "        if len(num_tub_labels_b4_filter) == 0:\n",
    "            # no filtering required if we already have no labels\n",
    "            print(f'no spindles detected in label {curr_mask_id}')\n",
    "            continue\n",
    "\n",
    "        # filter and labels smaller or larger than the mimum and maximum expected label sizes\n",
    "        min_thrsh_size = 500\n",
    "        max_thrsh_size = 5000       \n",
    "        if len(num_tub_labels_b4_filter) > 1:\n",
    "            thresh_mask = morphology.remove_small_objects(thresh_mask, min_size=100, connectivity=1)\n",
    "            thresh_mask = remove_large_objects(thresh_mask, max_size=max_thrsh_size)\n",
    "\n",
    "        # get the number of labels after filtering\n",
    "        remaining_labels = [label for label in np.unique(thresh_mask) if label != 0]\n",
    "\n",
    "        if len(remaining_labels) == 0:\n",
    "            print(f'no spindles detected in mask {curr_mask_id}')\n",
    "            continue\n",
    "\n",
    "        if len(remaining_labels) >= 1:\n",
    "\n",
    "            # calculate properties of remaining labels\n",
    "            props = regionprops_table(thresh_mask, properties=('area',\n",
    "                                                                'axis_major_length',\n",
    "                                                                'axis_minor_length',\n",
    "                                                                'label'))\n",
    "            props_df = pd.DataFrame(props)\n",
    "\n",
    "            # for each remaining label, calculate density and distance to cell centroid\n",
    "            for label_num in remaining_labels:\n",
    "                label_coords = np.column_stack(np.where(thresh_mask == label_num))\n",
    "                label_centroid = label_coords.mean(axis=0)\n",
    "                dist = spatial.distance.euclidean(cell_centroid, label_centroid)\n",
    "                props_df.loc[props_df['label'] == label_num, 'dist_to_cell'] = dist\n",
    "\n",
    "                label_density = find_label_density(label_coords)\n",
    "                props_df.loc[props_df['label'] == label_num, 'density'] = label_density\n",
    "\n",
    "            # convert to array and ask classifier to classify\n",
    "            for label_num in remaining_labels:\n",
    "                stats = props_df.loc[props_df['label'] == label_num]\n",
    "                stats = stats.drop(columns=['label'])\n",
    "                vals = stats.values\n",
    "\n",
    "                # remove the label if the classifier isn't >90% confident.\n",
    "                spindle_prediction = classifier.predict(vals)\n",
    "                print(f'spindle prediction for label {label_num} in cell {curr_mask_id} of embryo {subdir}: {spindle_prediction}')\n",
    "                if not spindle_prediction == 1:\n",
    "                    thresh_mask[thresh_mask == label_num] = 0\n",
    "                \n",
    "        # get a final label count\n",
    "        final_labels = [l for l in np.unique(thresh_mask) if l != 0]\n",
    "\n",
    "        if len(final_labels) == 0 or len(final_labels) > 1:\n",
    "            print(f'unsatisfactory spindle segmentation in mask {curr_mask_id}')\n",
    "            continue\n",
    "\n",
    "        # define mask save directory\n",
    "        mask_save_dir = os.path.join(emb_save_dir, f'cell_{curr_mask_id}')\n",
    "        if not os.path.exists(mask_save_dir):\n",
    "            os.mkdir(mask_save_dir)\n",
    "\n",
    "        # get the spindle coordinates and centroid\n",
    "        spindle_label_ID = remaining_labels[0]\n",
    "\n",
    "        spindle_coords = np.column_stack(np.where(thresh_mask == spindle_label_ID))\n",
    "        spindle_centroid = spindle_coords.mean(axis=0)\n",
    "        spindle_long_vect, spindle_long_line = get_long_axis(thresh_mask)\n",
    "\n",
    "        # get the distance between the centroids, and the angles between the long axes\n",
    "        dist = spatial.distance.euclidean(cell_centroid, spindle_centroid)\n",
    "        ang = vg.angle(spindle_long_vect, cell_long_vect)\n",
    "\n",
    "        # populate the viewer \n",
    "        viewer.add_labels(eroded_mask, name='eroded_mask', blending='additive', visible=False)\n",
    "        viewer.add_labels(cubed_label, name='curr_mask_cube', blending='additive')\n",
    "        viewer.add_image(cubed_tub, name='curr_tub_cube', blending='additive', visible=False)\n",
    "        viewer.add_image(cubed_tub_raw, name='curr_tub_raw_cube', blending='additive', visible=False)\n",
    "        viewer.add_image(cubed_PI, name='curr_PI_cube', blending='additive', visible=False)\n",
    "        viewer.add_labels(thresh_mask, name='thresh_mask', blending='additive')\n",
    "        viewer.add_points(cell_centroid, name='spindle centroid', face_color='magenta', blending='additive')\n",
    "        viewer.add_points(spindle_centroid, name='spindle centroid', face_color='green', blending='additive')\n",
    "        viewer.add_shapes(cell_long_line, shape_type='line', name='cell long axis', edge_color='red', blending='additive')\n",
    "        viewer.add_shapes(spindle_long_line, shape_type='line', name='spindle long axis', edge_color='blue', blending='additive')\n",
    "\n",
    "        images_and_layers = ['curr_mask_cube',\n",
    "                            'curr_tub_cube',\n",
    "                            'curr_tub_raw_cube',\n",
    "                            'curr_PI_cube',\n",
    "                            'eroded_mask',\n",
    "                            'thresh_mask']\n",
    "\n",
    "        # save the tif compatible layers as tifs\n",
    "        for item in images_and_layers:\n",
    "            viewer.layers[item].save(os.path.join(mask_save_dir, item + '.tif'))\n",
    "\n",
    "        # save the arrays as txt files\n",
    "        np.savetxt(os.path.join(mask_save_dir, 'spindle_centroid.txt'), spindle_centroid)\n",
    "        np.savetxt(os.path.join(mask_save_dir, 'cell_centroid.txt'), cell_centroid)\n",
    "        np.savetxt(os.path.join(mask_save_dir, 'spindle_long_axis.txt'), spindle_long_line)\n",
    "        \n",
    "    print(f'finished with embryo {subdir}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import label\n",
    "\n",
    "\n",
    "def calculate_geometries(curr_mask_id):\n",
    "\n",
    "    # start with a fresh slate\n",
    "    wipe_layers(viewer)\n",
    "    results[curr_mask_id] = []\n",
    "\n",
    "\n",
    "    # get the coordinate of the bounding cube for the current mask ID. Apply it to the labels and images\n",
    "    cube_dims = get_cube(masks, curr_mask_id)\n",
    "    cubed_label = apply_cube(curr_mask, cube_dims)\n",
    "    cubed_tub = apply_cube(tub, cube_dims)\n",
    "    cubed_tub_raw = apply_cube(tub_raw, cube_dims)\n",
    "    cubed_PI = apply_cube(pi, cube_dims)\n",
    "\n",
    "    # erode the mask to eliminate some cortical signal\n",
    "    eroded_mask = binary_erosion(cubed_label, footprint=np.ones((3, 3, 3)))\n",
    "    for i in range(10):\n",
    "        eroded_mask = binary_erosion(eroded_mask)\n",
    "\n",
    "    # get the tubulin signal from the remaining region and define an Otsu threshold\n",
    "    remaining_tub = np.zeros(shape=cubed_label.shape)\n",
    "    remaining_tub[eroded_mask] = cubed_tub[eroded_mask]\n",
    "    remaining_vals = cubed_tub[eroded_mask].ravel()\n",
    "    thresh_val = threshold_otsu(remaining_vals)\n",
    "    thresh_mask = label(remaining_tub > thresh_val)\n",
    "\n",
    "    # filter and labels smaller or larger than the mimum and maximum expected label sizes\n",
    "    min_thrsh_size = 500\n",
    "    max_thrsh_size = 5000\n",
    "    num_tub_labels_b4_filter = [label for label in np.unique(thresh_mask) if label != 0]\n",
    "\n",
    "    if len(num_tub_labels_b4_filter) == 0:\n",
    "        # no filtering required if we already have no labels\n",
    "        print(f'no spindles detected in label {curr_mask_id}')\n",
    "        return\n",
    "\n",
    "    if len(num_tub_labels_b4_filter) == 1:\n",
    "        # remove_small_objects will complain about this, so let's just pass it by remove_large_objects\n",
    "        thresh_mask = remove_large_objects(thresh_mask, max_size=max_thrsh_size)\n",
    "\n",
    "    if len(num_tub_labels_b4_filter) > 1:\n",
    "        # here it's likely that we have both small and large objects coontaminating\n",
    "        thresh_mask = morphology.remove_small_objects(thresh_mask, min_size=min_thrsh_size, connectivity=1)\n",
    "        thresh_mask = remove_large_objects(thresh_mask, max_size=max_thrsh_size)\n",
    "\n",
    "    # get the number of labels after filtering\n",
    "    remaining_labels = [label for label in np.unique(thresh_mask) if label != 0]\n",
    "    if len(remaining_labels) > 1:\n",
    "        print('more than one region remaining!')\n",
    "        return\n",
    "\n",
    "    if len(remaining_labels) == 0:\n",
    "        print(f'no spindles detected in mask {curr_mask_id}')\n",
    "        return\n",
    "\n",
    "    # get the spindle coordinates and centroid\n",
    "    spindle_label_ID = remaining_labels[0]\n",
    "    '''\n",
    "    record the spindle properties so we can make sure we're not analyzing any crazy shapes\n",
    "    '''\n",
    "    spindle_coords = np.column_stack(np.where(thresh_mask == spindle_label_ID))\n",
    "    spindle_centroid = spindle_coords.mean(axis=0)\n",
    "    spindle_long_vect, spindle_long_line = get_long_axis(thresh_mask)\n",
    "\n",
    "    # get the mask coordinates, centroid, and long axis\n",
    "    mask_coords = np.column_stack(np.where(cubed_label == True))\n",
    "    cell_centroid = mask_coords.mean(axis=0)\n",
    "    cell_long_vect, cell_long_line = get_long_axis(cubed_label)\n",
    "\n",
    "    # get the distance between the centroids, and the angles between the long axes\n",
    "    dist = spatial.distance.euclidean(cell_centroid, spindle_centroid)\n",
    "    ang = vg.angle(spindle_long_vect, cell_long_vect)\n",
    "    results[curr_mask_id].append(dist)\n",
    "    results[curr_mask_id].append(ang)\n",
    "\n",
    "    # make a save directory for this mask\n",
    "    if cntrl:\n",
    "        emb_save_dir = os.path.join(data_save_dir, f'Cntrl_E{emb_num}')\n",
    "    else:\n",
    "        emb_save_dir = os.path.join(data_save_dir, f'Exp_E{emb_num}')\n",
    "    if not os.path.exists(emb_save_dir):\n",
    "        os.makedirs(emb_save_dir)\n",
    "    \n",
    "    save_dir = os.path.join(emb_save_dir, f'{curr_mask_id}')\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "\n",
    "    # populate the viewer \n",
    "    viewer.add_labels(eroded_mask, name='eroded_mask', blending='additive', visible=False)\n",
    "    viewer.add_labels(cubed_label, name='curr_mask_cube', blending='additive')\n",
    "    viewer.add_image(cubed_tub, name='curr_tub_cube', blending='additive', visible=False)\n",
    "    viewer.add_image(cubed_tub_raw, name='curr_tub_raw_cube', blending='additive', visible=False)\n",
    "    viewer.add_image(cubed_PI, name='curr_PI_cube', blending='additive', visible=False)\n",
    "    viewer.add_labels(thresh_mask, name='thresh_mask', blending='additive')\n",
    "    viewer.add_points(cell_centroid, name='spindle centroid', face_color='magenta', blending='additive')\n",
    "    viewer.add_points(spindle_centroid, name='spindle centroid', face_color='green', blending='additive')\n",
    "    viewer.add_shapes(cell_long_line, shape_type='line', name='cell long axis', edge_color='red', blending='additive')\n",
    "    viewer.add_shapes(spindle_long_line, shape_type='line', name='spindle long axis', edge_color='blue', blending='additive')\n",
    "\n",
    "    images_and_layers = ['curr_mask_cube',\n",
    "                        'curr_tub_cube',\n",
    "                        'curr_tub_raw_cube',\n",
    "                        'curr_PI_cube',\n",
    "                        'eroded_mask',\n",
    "                        'thresh_mask']\n",
    "\n",
    "    # save the tif compatible layers as tifs\n",
    "    for item in images_and_layers:\n",
    "        viewer.layers[item].save(os.path.join(save_dir, item + '.tif'))\n",
    "\n",
    "    # save the arrays as txt files\n",
    "    np.savetxt(os.path.join(save_dir, 'spindle_centroid.txt'), spindle_centroid)\n",
    "    np.savetxt(os.path.join(save_dir, 'cell_centroid.txt'), cell_centroid)\n",
    "    np.savetxt(os.path.join(save_dir, 'spindle_long_axis.txt'), spindle_long_line)\n",
    "\n",
    "base_dir = '/Volumes/bigData/wholeMount_volDist/220712_Fix_Emb_Flvw_Chn1GAP_PI_aTub647_Processed/N2V_Denoised/16bit_scaleZ_sbdl2' \n",
    "\n",
    "cntrl = False\n",
    "emb_nums = ['06']\n",
    "for emb_num in emb_nums:\n",
    "\n",
    "    if cntrl == True:\n",
    "        emb_type = 'Cntrl'\n",
    "        segmentations_name = f'220712_Fix_Emb_Flvw_Chn1GAP_PI_aTub647_{emb_type}_E{emb_num}-Z01_PI_16bit_scaleZ_sbdl2_16bit_seg.npy'\n",
    "        dog_tub_name = f'220712_Fix_Emb_Flvw_Chn1GAP_PI_aTub647_{emb_type}_E{emb_num}-Z01_Tub_16bit_scaleZ_sbdl2_16bit.tif'\n",
    "        raw_tub_name = f'220712_Fix_Emb_Flvw_Chn1GAP_PI_aTub647_{emb_type}_E{emb_num}-Z01_Tub_16bit_scaleZ.tif'\n",
    "        pi_name = f'220712_Fix_Emb_Flvw_Chn1GAP_PI_aTub647_{emb_type}_E{emb_num}-Z01_PI_16bit_scaleZ_sbdl2_16bit.tif'\n",
    "\n",
    "        masks = np.load(os.path.join(base_dir, segmentations_name), allow_pickle=True).item()['masks']\n",
    "        tub = imread(os.path.join(base_dir, dog_tub_name))\n",
    "        tub_raw = imread(os.path.join(base_dir, raw_tub_name))\n",
    "        pi = imread(os.path.join(base_dir, pi_name))\n",
    "\n",
    "    if cntrl == False:\n",
    "        emb_type = 'Exp'\n",
    "        segmentations_name = f'220712_Fix_Emb_Flvw_Chn1GAP_PI_aTub647_{emb_type}_E{emb_num}-Z01_PI_16bit_scaleZ_sbdl2_16bit_seg.npy'\n",
    "        dog_tub_name = f'220712_Fix_Emb_Flvw_Chn1GAP_PI_aTub647_{emb_type}_E{emb_num}-Z01_Tub_16bit_scaleZ_sbdl2_16bit.tif'\n",
    "        raw_tub_name = f'220712_Fix_Emb_Flvw_Chn1GAP_PI_aTub647_{emb_type}_E{emb_num}-Z01_Tub_16bit_scaleZ.tif'\n",
    "        pi_name = f'220712_Fix_Emb_Flvw_Chn1GAP_PI_aTub647_{emb_type}_E{emb_num}-Z01_PI_16bit_scaleZ_sbdl2_16bit.tif'\n",
    "\n",
    "        masks = np.load(os.path.join(base_dir, segmentations_name), allow_pickle=True).item()['masks']\n",
    "        tub = imread(os.path.join(base_dir, dog_tub_name))\n",
    "        tub_raw = imread(os.path.join(base_dir, raw_tub_name))\n",
    "        pi = imread(os.path.join(base_dir, pi_name))\n",
    "\n",
    "    ########################################################################################################################\n",
    "\n",
    "    minimum_size = 250000\n",
    "    maximum_size = 1000000\n",
    "    minimum_density = 0.21\n",
    "\n",
    "    filtered_masks = clear_border(masks)\n",
    "    filtered_masks = morphology.remove_small_objects(filtered_masks, min_size=minimum_size, connectivity=1)\n",
    "    filtered_masks = remove_large_objects(filtered_masks, max_size=maximum_size)\n",
    "    remaining_labels = [label for label in np.unique(filtered_masks) if label != 0]\n",
    "    print('Calculating point clouds...')\n",
    "    label_pcs = [return_points(masks, label_ID) for label_ID in tqdm(remaining_labels)]\n",
    "    densities = [find_label_density(pc) for pc in label_pcs]\n",
    "\n",
    "    for ind, id in enumerate(remaining_labels):\n",
    "        if id in remaining_labels and densities[ind] < minimum_density:\n",
    "            filtered_masks[filtered_masks == id] = 0\n",
    "\n",
    "    ########################################################################################################################\n",
    "\n",
    "\n",
    "    final_labels = [label for label in np.unique(filtered_masks) if label != 0]\n",
    "    main_save_dir = '/Users/bementmbp/Desktop/autosave2' \n",
    "    results = {}\n",
    "\n",
    "    def calculate_geometries(curr_mask_id):\n",
    "\n",
    "        # start with a fresh slate\n",
    "        wipe_layers()\n",
    "        results[curr_mask_id] = []\n",
    "        curr_mask = masks == curr_mask_id\n",
    "\n",
    "        # get the coordinate of the bounding cube for the current mask ID. Apply it to the labels and images\n",
    "        cube_dims = get_cube(masks, curr_mask_id)\n",
    "        cubed_label = apply_cube(curr_mask, cube_dims)\n",
    "        cubed_tub = apply_cube(tub, cube_dims)\n",
    "        cubed_tub_raw = apply_cube(tub_raw, cube_dims)\n",
    "        cubed_PI = apply_cube(pi, cube_dims)\n",
    "\n",
    "        # erode the mask to eliminate some cortical signal\n",
    "        eroded_mask = binary_erosion(cubed_label, footprint=np.ones((3, 3, 3)))\n",
    "        for i in range(10):\n",
    "            eroded_mask = binary_erosion(eroded_mask)\n",
    "\n",
    "        # get the tubulin signal from the remaining region and define an Otsu threshold\n",
    "        remaining_tub = np.zeros(shape=cubed_label.shape)\n",
    "        remaining_tub[eroded_mask] = cubed_tub[eroded_mask]\n",
    "        remaining_vals = cubed_tub[eroded_mask].ravel()\n",
    "        thresh_val = threshold_otsu(remaining_vals)\n",
    "        thresh_mask = label(remaining_tub > thresh_val)\n",
    "\n",
    "        # filter and labels smaller or larger than the mimum and maximum expected label sizes\n",
    "        min_thrsh_size = 500\n",
    "        max_thrsh_size = 5000\n",
    "        num_tub_labels_b4_filter = [label for label in np.unique(thresh_mask) if label != 0]\n",
    "\n",
    "        if len(num_tub_labels_b4_filter) == 0:\n",
    "            # no filtering required if we already have no labels\n",
    "            print(f'no spindles detected in label {curr_mask_id}')\n",
    "            return\n",
    "\n",
    "        if len(num_tub_labels_b4_filter) == 1:\n",
    "            # remove_small_objects will complain about this, so let's just pass it by remove_large_objects\n",
    "            thresh_mask = remove_large_objects(thresh_mask, max_size=max_thrsh_size)\n",
    "\n",
    "        if len(num_tub_labels_b4_filter) > 1:\n",
    "            # here it's likely that we have both small and large objects coontaminating\n",
    "            thresh_mask = morphology.remove_small_objects(thresh_mask, min_size=min_thrsh_size, connectivity=1)\n",
    "            thresh_mask = remove_large_objects(thresh_mask, max_size=max_thrsh_size)\n",
    "\n",
    "        # get the number of labels after filtering\n",
    "        remaining_labels = [label for label in np.unique(thresh_mask) if label != 0]\n",
    "        if len(remaining_labels) > 1:\n",
    "            print('more than one region remaining!')\n",
    "            return\n",
    "\n",
    "        if len(remaining_labels) == 0:\n",
    "            print(f'no spindles detected in mask {curr_mask_id}')\n",
    "            return\n",
    "\n",
    "        # get the spindle coordinates and centroid\n",
    "        spindle_label_ID = remaining_labels[0]\n",
    "        '''\n",
    "        record the spindle properties so we can make sure we're not analyzing any crazy shapes\n",
    "        '''\n",
    "        spindle_coords = np.column_stack(np.where(thresh_mask == spindle_label_ID))\n",
    "        spindle_centroid = spindle_coords.mean(axis=0)\n",
    "        spindle_long_vect, spindle_long_line = get_long_axis(thresh_mask)\n",
    "\n",
    "        # get the mask coordinates, centroid, and long axis\n",
    "        mask_coords = np.column_stack(np.where(cubed_label == True))\n",
    "        cell_centroid = mask_coords.mean(axis=0)\n",
    "        cell_long_vect, cell_long_line = get_long_axis(cubed_label)\n",
    "\n",
    "        # get the distance between the centroids, and the angles between the long axes\n",
    "        dist = spatial.distance.euclidean(cell_centroid, spindle_centroid)\n",
    "        ang = vg.angle(spindle_long_vect, cell_long_vect)\n",
    "        results[curr_mask_id].append(dist)\n",
    "        results[curr_mask_id].append(ang)\n",
    "\n",
    "        # make a save directory for this mask\n",
    "        if cntrl:\n",
    "            emb_save_dir = os.path.join(main_save_dir, f'Cntrl_E{emb_num}')\n",
    "        else:\n",
    "            emb_save_dir = os.path.join(main_save_dir, f'Exp_E{emb_num}')\n",
    "        if not os.path.exists(emb_save_dir):\n",
    "            os.makedirs(emb_save_dir)\n",
    "        \n",
    "        save_dir = os.path.join(emb_save_dir, f'{curr_mask_id}')\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.mkdir(save_dir)\n",
    "\n",
    "        # populate the viewer \n",
    "        viewer.add_labels(eroded_mask, name='eroded_mask', blending='additive', visible=False)\n",
    "        viewer.add_labels(cubed_label, name='curr_mask_cube', blending='additive')\n",
    "        viewer.add_image(cubed_tub, name='curr_tub_cube', blending='additive', visible=False)\n",
    "        viewer.add_image(cubed_tub_raw, name='curr_tub_raw_cube', blending='additive', visible=False)\n",
    "        viewer.add_image(cubed_PI, name='curr_PI_cube', blending='additive', visible=False)\n",
    "        viewer.add_labels(thresh_mask, name='thresh_mask', blending='additive')\n",
    "        viewer.add_points(cell_centroid, name='spindle centroid', face_color='magenta', blending='additive')\n",
    "        viewer.add_points(spindle_centroid, name='spindle centroid', face_color='green', blending='additive')\n",
    "        viewer.add_shapes(cell_long_line, shape_type='line', name='cell long axis', edge_color='red', blending='additive')\n",
    "        viewer.add_shapes(spindle_long_line, shape_type='line', name='spindle long axis', edge_color='blue', blending='additive')\n",
    "\n",
    "        images_and_layers = ['curr_mask_cube',\n",
    "                            'curr_tub_cube',\n",
    "                            'curr_tub_raw_cube',\n",
    "                            'curr_PI_cube',\n",
    "                            'eroded_mask',\n",
    "                            'thresh_mask']\n",
    "\n",
    "        # save the tif compatible layers as tifs\n",
    "        for item in images_and_layers:\n",
    "            viewer.layers[item].save(os.path.join(save_dir, item + '.tif'))\n",
    "\n",
    "        # save the arrays as txt files\n",
    "        np.savetxt(os.path.join(save_dir, 'spindle_centroid.txt'), spindle_centroid)\n",
    "        np.savetxt(os.path.join(save_dir, 'cell_centroid.txt'), cell_centroid)\n",
    "        np.savetxt(os.path.join(save_dir, 'spindle_long_axis.txt'), spindle_long_line)\n",
    "\n",
    "    for curr_mask_id in final_labels:\n",
    "        calculate_geometries(curr_mask_id)\n",
    "    \n",
    "    print(f'finished with {emb_num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = '/Users/bementmbp/Desktop/autosave2/Exp_E02/46/curr_tub_raw_cube.tif' \n",
    "m = '/Users/bementmbp/Desktop/Scripts/volume-distribution/spindle_classifier/raw_training_data/95/curr_mask_cube.tif'\n",
    "raw = imread(p)\n",
    "cell_mask = imread(m).astype('bool')\n",
    "\n",
    "\n",
    "\n",
    "thresh = threshold_otsu(raw)\n",
    "binary = np.zeros(raw.shape)\n",
    "binary[raw > thresh] = 1\n",
    "thresh_labels = label(binary)\n",
    "thresh_labels = morphology.remove_small_objects(thresh_labels, min_size=100, connectivity=1)\n",
    "\n",
    "viewer.add_image(raw, name='raw', blending='additive')\n",
    "viewer.add_labels(thresh_labels, name='thresh_labels', blending='additive')\n",
    "viewer.add_labels(cell_mask, name='cell_mask', blending='additive')\n",
    "\n",
    "# load the classifier\n",
    "classifier_path = os.path.join(os.getcwd(), 'spindle_classifier/spindle_classifier.joblib')\n",
    "classifier = joblib.load(classifier_path)\n",
    "\n",
    "# get the cell mask centroid\n",
    "mask_coords = np.column_stack(np.where(cell_mask == True))\n",
    "cell_centroid = mask_coords.mean(axis=0)\n",
    "\n",
    "props = regionprops_table(thresh_labels, properties=('area',\n",
    "                                                    'axis_major_length',\n",
    "                                                    'axis_minor_length',\n",
    "                                                    'label'))\n",
    "props_df = pd.DataFrame(props)\n",
    "\n",
    "remaining_labels = [l for l in np.unique(thresh_labels) if l != 0]\n",
    "for label_num in remaining_labels:\n",
    "    label_coords = np.column_stack(np.where(thresh_labels == label_num))\n",
    "    label_centroid = label_coords.mean(axis=0)\n",
    "    dist = spatial.distance.euclidean(cell_centroid, label_centroid)\n",
    "    props_df.loc[props_df['label'] == label_num, 'dist_to_cell'] = dist\n",
    "\n",
    "    label_density = find_label_density(label_coords)\n",
    "    props_df.loc[props_df['label'] == label_num, 'density'] = label_density\n",
    "\n",
    "for label_num in remaining_labels:\n",
    "    stats = props_df.loc[props_df['label'] == label_num]\n",
    "    stats = stats.drop(columns=['label'])\n",
    "    vals = stats.values\n",
    "    print(f'prediction for label {label_num}: {classifier.predict_proba(vals)}')\n",
    "\n",
    "    print(f'spindle prediction: {classifier.predict_proba(vals)[0][1]}')\n",
    "\n",
    "    if not classifier.predict_proba(vals)[0][1] > 0.9:\n",
    "        thresh_labels[thresh_labels == label_num] = 0\n",
    "    \n",
    "viewer.add_labels(thresh_labels, name='cleaned labels', blending='additive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('napari_apoc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9332436963653b5df92bf2f53404d912d66b2e5a7a0f130fd2cb37eb34a8db49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
