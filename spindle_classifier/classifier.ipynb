{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a random forest classifier to predict whether segmented shapes are spindles or noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import napari\n",
    "from tifffile import imread, imwrite\n",
    "from skimage import morphology\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.morphology import binary_erosion\n",
    "from skimage.filters import threshold_otsu\n",
    "from scipy import spatial\n",
    "from skimage.measure import label, regionprops, regionprops_table\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import pandas as pd\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def wipe_layers(viewer_name):\n",
    "    '''\n",
    "    Delete all layers in the viewer objected\n",
    "    '''\n",
    "    layers = viewer_name.layers\n",
    "    while len(layers) > 0:\n",
    "        layers.remove(layers[0])\n",
    "\n",
    "def remove_large_objects(labels_array: np.ndarray, max_size: int) -> np.ndarray:\n",
    "    ''' \n",
    "    Remove all objects in a mask above a specific threshold\n",
    "    '''\n",
    "    out = np.copy(labels_array)\n",
    "    component_sizes = np.bincount(labels_array.ravel()) # count the number of pixels in different labels\n",
    "    too_big = component_sizes > max_size\n",
    "    too_big_mask = too_big[labels_array]\n",
    "    out[too_big_mask] = 0\n",
    "    return out\n",
    "\n",
    "def return_points(labels_array: np.ndarray, label_ID: int) -> np.ndarray:\n",
    "    '''\n",
    "    Return the points in a mask that belong to a specific label\n",
    "    ---\n",
    "    Parameters:\n",
    "    labels_array: np.ndarray an ndArray of labels\n",
    "    label_ID: int the label ID of the label whos points you want to calculate\n",
    "    ---\n",
    "    Returns:\n",
    "    points: np.ndarray an ndArray of shape (n,3) where n is the number of points in the label\n",
    "    and dim1 is the x,y,z coordinates of the points\n",
    "    '''\n",
    "    points = np.column_stack(np.where(labels_array == label_ID))\n",
    "    return points\n",
    "\n",
    "def find_label_density(label_points: np.ndarray) -> float:\n",
    "    '''\n",
    "    Calculate the bounding box for a point cloud and return the density of points in the bounding box\n",
    "    ---\n",
    "    Parameters:\n",
    "    label_points: np.ndarray the array point coordinates for a given label\n",
    "    ---\n",
    "    Returns:\n",
    "    np.nan if the label is 0, or if the label has no length\n",
    "    density (float) the number of points in the label divided by the volume of the bounding box\n",
    "    '''\n",
    "\n",
    "    x = label_points.T[0]\n",
    "    y = label_points.T[1]\n",
    "    z = label_points.T[2]\n",
    "    num_points = len(x)\n",
    "    x_min = np.min(x)\n",
    "    x_max = np.max(x)\n",
    "    y_min = np.min(y)\n",
    "    y_max = np.max(y)\n",
    "    z_min = np.min(z)\n",
    "    z_max = np.max(z)\n",
    "    # add 1 to prevent division by 0\n",
    "    x_range = (x_max - x_min) + 1\n",
    "    y_range = (y_max - y_min) + 1\n",
    "    z_range = (z_max - z_min) + 1\n",
    "    vol = x_range * y_range * z_range\n",
    "    density = num_points / vol\n",
    "    return density\n",
    "\n",
    "def print_label_props(source: np.ndarray, label_num: int) -> None:\n",
    "    '''\n",
    "    Print the properties of a label in a mask\n",
    "    ---\n",
    "    Parameters:\n",
    "    source: np.ndarray the mask containing the label\n",
    "    label_num: int the label number of the label you want to print the properties of\n",
    "    ---\n",
    "    Returns:\n",
    "    None\n",
    "    '''\n",
    "    label_points = return_points(source, label_num)\n",
    "    density = find_label_density(label_points)\n",
    "    size = label_points.shape[0]\n",
    "    print(f'Label {label_num} has:')\n",
    "    print(f'{size:,} points.')\n",
    "    print(f'density of {round(density,4):,}')\n",
    "\n",
    "def view_saved_files(file_path: str) -> None:\n",
    "    ''' \n",
    "    Fxn for visualizing saved output files.\n",
    "    '''\n",
    "    dedicated_file_viewer = napari.Viewer()\n",
    "    contents = [c for c in os.listdir(file_path) if not c.startswith('.')]\n",
    "    for content in contents:\n",
    "        if content.endswith('.tif'):\n",
    "            if 'tub' in content or 'PI' in content:\n",
    "                dedicated_file_viewer.add_image(imread(os.path.join(file_path, content)), name=content.split('.')[0], blending='additive', visible=False)\n",
    "            else:\n",
    "                dedicated_file_viewer.add_labels(imread(os.path.join(file_path, content)), name=content.split('.')[0], blending='additive')\n",
    "        elif content.endswith('.txt'):\n",
    "            nums = np.loadtxt(os.path.join(file_path, content))\n",
    "            if nums.ndim == 1:\n",
    "                dedicated_file_viewer.add_points(nums, name=content.split('.')[0], face_color='white', blending='additive')\n",
    "            elif nums.ndim == 2:\n",
    "                dedicated_file_viewer.add_shapes(nums, shape_type='line', name=content.split('.')[0], edge_color='white', blending='additive')\n",
    "        else:\n",
    "            print(f'file \"{content}\" not imported to viewer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt\n",
    "propsviewer = napari.Viewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this folder contains raw data cubes and ground truth masks (or no masks, no good ones were found)\n",
    "main_folder = os.path.join(os.getcwd(), 'raw_training_data')\n",
    "\n",
    "# list of subfolders\n",
    "subfolders = [f for f in os.listdir(main_folder) if not f.startswith('.')]\n",
    "\n",
    "# list to hold all the properties for each cell cube in the training set\n",
    "label_properties = []\n",
    "\n",
    "for curr_cell_num in tqdm(subfolders):\n",
    "\n",
    "    # get the path to the relevant cell folder and and data files\n",
    "    base_dir = f'{os.getcwd()}/raw_training_data/{curr_cell_num}'\n",
    "    valid_mask_name = 'thresh_mask.tif' \n",
    "    dog_tub_name = 'curr_tub_cube.tif' \n",
    "    cell_mask_name = 'curr_mask_cube.tif'\n",
    "    eroded_mask_name = 'eroded_mask.tif'\n",
    "\n",
    "    # load the data\n",
    "    valid_mask = imread(os.path.join(base_dir, valid_mask_name))\n",
    "    cubed_tub = imread(os.path.join(base_dir, dog_tub_name))\n",
    "    cubed_label = imread(os.path.join(base_dir, cell_mask_name)).astype('bool')\n",
    "    eroded_mask = imread(os.path.join(base_dir, eroded_mask_name)).astype('bool')\n",
    "\n",
    "    # get the tubulin signal from the eroded mask region and define an Otsu threshold\n",
    "    remaining_tub = np.zeros(shape=cubed_tub.shape)\n",
    "    remaining_tub[eroded_mask] = cubed_tub[eroded_mask]\n",
    "    remaining_vals = cubed_tub[eroded_mask].ravel()\n",
    "    thresh_val = threshold_otsu(remaining_vals)\n",
    "    thresh_mask = label(remaining_tub > thresh_val)\n",
    "\n",
    "    # get the label properties\n",
    "    props = regionprops_table(thresh_mask, properties=('area',\n",
    "                                                    'axis_major_length',\n",
    "                                                    'axis_minor_length',\n",
    "                                                    'label'))\n",
    "    props_df = pd.DataFrame(props)\n",
    "\n",
    "    # attempt to find the ground truth label value. If none exists, assign to None\n",
    "    try:\n",
    "        valid_ID = [num for num in np.unique(valid_mask) if num != 0][0]\n",
    "    except IndexError:\n",
    "        valid_ID = None\n",
    "\n",
    "    # make a new column named \"spindle\" and assign to 1 if the label value is 1 otherwise 0\n",
    "    props_df['spindle'] = (props_df['label'] == valid_ID).astype(int)\n",
    "\n",
    "    # get the mask coordinates and centroid\n",
    "    mask_coords = np.column_stack(np.where(cubed_label == True))\n",
    "    cell_centroid = mask_coords.mean(axis=0)\n",
    "\n",
    "    # get a list of remaining label IDs. Iterate through them to find the distance to the \n",
    "    # cell controid and the label density\n",
    "    remaining_labels = [l for l in np.unique(thresh_mask) if label != 0]\n",
    "    for label_num in remaining_labels:\n",
    "        label_coords = np.column_stack(np.where(thresh_mask == label_num))\n",
    "        label_centroid = label_coords.mean(axis=0)\n",
    "        dist = spatial.distance.euclidean(cell_centroid, label_centroid)\n",
    "        props_df.loc[props_df['label'] == label_num, 'dist_to_cell'] = dist\n",
    "\n",
    "        label_density = find_label_density(label_coords)\n",
    "        props_df.loc[props_df['label'] == label_num, 'density'] = label_density\n",
    "\n",
    "    # remove label column, convert to list of dicts and append to label_properties list\n",
    "    props_df.drop(columns=['label'], inplace=True)\n",
    "    props_list = props_df.to_dict('records')\n",
    "    for property_dict in props_list:\n",
    "        label_properties.append(property_dict)\n",
    "\n",
    "# merge all data into one dataframe\n",
    "df = pd.DataFrame(label_properties)\n",
    "df = df[['area', 'axis_major_length', 'axis_minor_length', 'dist_to_cell', 'density', 'spindle']]\n",
    "\n",
    "# define the properties and classes\n",
    "X = df.iloc[:,0:5].values\n",
    "y = df.iloc[:,5].values\n",
    "\n",
    "# split into training and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# define and train the classifier\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "classifier.fit(X_train, Y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "a = accuracy_score(Y_test, y_pred)\n",
    "print(f'accuracy: {a}')\n",
    "print(classification_report(Y_test, y_pred))\n",
    "print(confusion_matrix(Y_test, y_pred))\n",
    "\n",
    "cwd = os.getcwd()\n",
    "joblib.dump(classifier, os.path.join(cwd, 'spindle_classifier.joblib'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# piecewise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this folder contains raw data cubes and ground truth masks (or no masks, no good ones were found)\n",
    "main_folder = os.path.join(os.getcwd(), 'raw_training_data')\n",
    "\n",
    "# list of subfolders\n",
    "subfolders = [f for f in os.listdir(main_folder) if not f.startswith('.')]\n",
    "\n",
    "# list to hold all the properties for each cell cube in the training set\n",
    "label_properties = []\n",
    "\n",
    "curr_cell_num = input()\n",
    "\n",
    "# get the path to the relevant cell folder and and data files\n",
    "base_dir = f'{os.getcwd()}/raw_training_data/{curr_cell_num}'\n",
    "valid_mask_name = 'thresh_mask.tif' \n",
    "dog_tub_name = 'curr_tub_cube.tif' \n",
    "cell_mask_name = 'curr_mask_cube.tif'\n",
    "eroded_mask_name = 'eroded_mask.tif'\n",
    "\n",
    "# load the data\n",
    "valid_mask = imread(os.path.join(base_dir, valid_mask_name))\n",
    "cubed_tub = imread(os.path.join(base_dir, dog_tub_name))\n",
    "cubed_label = imread(os.path.join(base_dir, cell_mask_name)).astype('bool')\n",
    "eroded_mask = imread(os.path.join(base_dir, eroded_mask_name)).astype('bool')\n",
    "\n",
    "# get the tubulin signal from the eroded mask region and define an Otsu threshold\n",
    "remaining_tub = np.zeros(shape=cubed_tub.shape)\n",
    "remaining_tub[eroded_mask] = cubed_tub[eroded_mask]\n",
    "remaining_vals = cubed_tub[eroded_mask].ravel()\n",
    "thresh_val = threshold_otsu(remaining_vals)\n",
    "thresh_mask = label(remaining_tub > thresh_val)\n",
    "\n",
    "# get the label properties\n",
    "props = regionprops_table(thresh_mask, properties=('area',\n",
    "                                                'axis_major_length',\n",
    "                                                'axis_minor_length',\n",
    "                                                'label'))\n",
    "props_df = pd.DataFrame(props)\n",
    "\n",
    "# attempt to find the ground truth label value. If none exists, assign to None\n",
    "try:\n",
    "    valid_ID = [num for num in np.unique(valid_mask) if num != 0][0]\n",
    "except IndexError:\n",
    "    valid_ID = None\n",
    "\n",
    "# make a new column named \"spindle\" and assign to 1 if the label value is 1 otherwise 0\n",
    "props_df['spindle'] = (props_df['label'] == valid_ID).astype(int)\n",
    "\n",
    "# get the mask coordinates and centroid\n",
    "mask_coords = np.column_stack(np.where(cubed_label == True))\n",
    "cell_centroid = mask_coords.mean(axis=0)\n",
    "\n",
    "# get a list of remaining label IDs. Iterate through them to find the distance to the \n",
    "# cell controid and the label density\n",
    "remaining_labels = [l for l in np.unique(thresh_mask) if label != 0]\n",
    "for label_num in remaining_labels:\n",
    "    label_coords = np.column_stack(np.where(thresh_mask == label_num))\n",
    "    label_centroid = label_coords.mean(axis=0)\n",
    "    dist = spatial.distance.euclidean(cell_centroid, label_centroid)\n",
    "    props_df.loc[props_df['label'] == label_num, 'dist_to_cell'] = dist\n",
    "\n",
    "    label_density = find_label_density(label_coords)\n",
    "    props_df.loc[props_df['label'] == label_num, 'density'] = label_density\n",
    "\n",
    "# remove label column, convert to list of dicts and append to label_properties list\n",
    "props_df.drop(columns=['label'], inplace=True)\n",
    "props_list = props_df.to_dict('records')\n",
    "for property_dict in props_list:\n",
    "    label_properties.append(property_dict)\n",
    "\n",
    "# merge all data into one dataframe\n",
    "df = pd.DataFrame(label_properties)\n",
    "df = df[['area', 'axis_major_length', 'axis_minor_length', 'dist_to_cell', 'density', 'spindle']]\n",
    "\n",
    "# define the properties and classes\n",
    "X = df.iloc[:,0:5].values\n",
    "y = df.iloc[:,5].values\n",
    "\n",
    "# split into training and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# define and train the classifier\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "classifier.fit(X_train, Y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "a = accuracy_score(Y_test, y_pred)\n",
    "print(f'accuracy: {a}')\n",
    "print(classification_report(Y_test, y_pred))\n",
    "print(confusion_matrix(Y_test, y_pred))\n",
    "\n",
    "cwd = os.getcwd()\n",
    "joblib.dump(classifier, os.path.join(cwd, 'spindle_classifier.joblib'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('napari_apoc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9332436963653b5df92bf2f53404d912d66b2e5a7a0f130fd2cb37eb34a8db49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
